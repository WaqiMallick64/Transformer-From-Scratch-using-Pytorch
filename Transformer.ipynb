{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-gXvUIx1_4A",
    "outputId": "7cb98533-7c1b-4671-efce-bd63dca447ff"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zNbc6NwGsbb6",
    "outputId": "9eca940f-d60b-4882-ba4c-e14d07a0c529"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olCbNmiTZQjh"
   },
   "source": [
    "LOADING THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639,
     "referenced_widgets": [
      "c6df47b9f4c1486c9f121e88220f7e17",
      "72d7c68cd9fe4c3f8f545bf0e6764557",
      "b7ae0eea5a3b4c37b14808d63508c23a",
      "708318d5db4a43fba6ad7e2783aec844",
      "c0556bfcb081483d9e9628b8ecdffe77",
      "5c95eafad5b64ad8bb4a2fe194316781",
      "23f5929fc2444d61944ce850153daf31",
      "29439393d18c443192e1fbdad47a7911",
      "c0d398c0c81943d685e43825cf5967ae",
      "46c59119ba44443abe348780b1718626",
      "a6cf3fa012aa4201b7ca45bbff19e0ba",
      "243307df9a094165b0c18b8286e5dd13",
      "8c5c5dc51a314746a281355e9f2510a6",
      "f2d4d4908bd94900a0f9f603def486ea",
      "cdb73a988cdf4e70803687fa4d9767f3",
      "21ec94a49e164779afa86ed5113cd552",
      "2e4f6d1c377247b8a0f1700209f324ff",
      "cb5e86fad65546c18112958ae82d46af",
      "7a9ad501f4054eff8415321c4a4941c9",
      "e4eb572e3f9840f98f2b0c6f6ddf3ba3",
      "7d0ea400c72845d7bd72212bd4d39509",
      "77277378b1bc4910a212d0487585123a",
      "882353e0ed914c5fae8cb610dee2d9ae",
      "1f6383661dd1494fa85f007f58eef9b5",
      "8c1f0c2156f24030819c0ebeb1afa019",
      "1e4ad84793924067be5e25af5818ccf3",
      "d192ad2d0acf43d4a685e30e3037d50a",
      "f99a2fe213fe44ecbd3985c10922dc4b",
      "dcf11ea7daf042b99c5da85a1584cd60",
      "ad43ee8708054b1db5c16fc2857f3af4",
      "d37758e85adc4ee3a3e62e7c0a98d5d2",
      "ff489463789c4750955fb6458786fbad",
      "13c8e77e41504eeebe9f51ce08a3700a",
      "fd5f8ab51075458c8b3c0b69eba60357",
      "a8c6f55766ce47e399bc3b75a5bfaa6f",
      "57ccce3a63e64cb6abf08ecb8710c0ea",
      "b0f80620656f4668a9754558e0c18ee8",
      "27a8e4a47d1044f7a97a1af58b551d41",
      "7c405d76ebcc4ac1accb93fca9e8827b",
      "241f49c7105749f5bd58ae903606e947",
      "39c5e29fcf814a428c0b7db06334858c",
      "d14269e0b3754baabf13856d61174744",
      "75404a9491d44867b46374170c96c177",
      "985ece378ebd48b59a971155b27b7373",
      "e32cd739f2ed4e9f8e00cfeb6796b469",
      "9e49029f58274ea2b0ea6e9b76179104",
      "838ceb426c174182b828fe4b8d303566",
      "ac46f2b2e98841f69de9690970e6839a",
      "03a553e972294bfcadf2e31290b96bfa",
      "0fd34e706da64dc180bef23a22afa494",
      "5aa505588cb349c9806c673d6b33a2ff",
      "aec767f8fb314df09d50666fb75a54ba",
      "543100eb398e4e3bb16e0db8d7425f7b",
      "056135fd240e4f40812f07e7fc26f168",
      "e615ff17149a40c6b146782982ace8c5",
      "5c8b0a2936b6420582db107f1dee0b1e",
      "a2b874c3cf2040efab87e59ac2433ee7",
      "e7aa24cd9781423a99b922221f2139d2",
      "534a3d4106a54f92989a3ab57b688452",
      "30a1d805e9514a4c815ef5041ac5f1db",
      "4cec3d9d676d4c4e8cb87433aa794801",
      "9c69ebe76c39464f8eeb33cdc6775098",
      "89b616d369ea4cceacccecd22fbf02f6",
      "1c65fc158bae4444902b5a0af36ea292",
      "0360cf4aa6994cdaab68da3b0df42a0c",
      "ed25cbf451bd4414a7df603bdedfd8b6",
      "7975cc80c4a942efb5ed8c6ea84ff881",
      "60f6b7b48c414a97ac70bbbdaa9ba181",
      "184a946545b941378be3c3703fdea70f",
      "8bbd80d162c248aab75341ae0ad22170",
      "42c3e3ff9c594794a2d08a02e8c1bb75",
      "744f82f16c6e4e8cb8a02e9d968213d8",
      "da861f800e4a4f4bb0b0da02986a80d1",
      "287b13f61f384ed2be0afaf958cb1fea",
      "8a12645ccfe44098a5dd43263d7d119d",
      "d077909b2e2644a1ae7827477598fffa",
      "adae1a7c97e446369752b10533b9413f",
      "3ea4577dbaec407db481762d159e998f",
      "6acbcb444ab6433f85007e7bdd038cb2",
      "214f9d7b16fb461ebed8f1f5de69ebbd",
      "d9356c8eda89497a86268a6d8a1fa4cb",
      "14e0e4b3a08440b2a17add71b53cd665",
      "12f1c39733854383875cf26b7ceb2834",
      "558e19208c03401da039a646324395a3",
      "7cc7eb7e73794ba7acd16642e5fe2662",
      "75a7ab06a0cd4e46b78b11a079061ca3",
      "042a02bf63504c9e89d09ad432ef6e33",
      "b7148b60ae0343809dbc3ddc6525bfbc",
      "7b74c9d49fb245b2831322519a186ae6",
      "f33ff4fd1fe54929bd02314fbb14effb",
      "145efdb4561e4e50b1731a0361bb9f29",
      "ed2afa2fc2c44a6dba860c0bb73f10ca",
      "ad50f2033a52440e83fe7fa817567ff1",
      "f834f11e088c4f04a588efc15b93dfec",
      "3cf54bf405e8432985036ef824e97720",
      "657eb4bb644b4f00a1be7a59607ffe08",
      "ffad91418d324002ba9643a56c204f34",
      "5ca75a2cdf954d969d1b94b9d5f1aece",
      "44848d95279145c781511a44f393dec1",
      "efced77666e14cc7a9e6816daee95e84",
      "56d5cdd499014665845602c28f0c43c5",
      "4e8d677f9b3e4947969c4767591d64f1",
      "b41aeca2a0da499bbe0ed8f610aeb0a0",
      "c34f15831cb849d9a6a4c781bae02dcc",
      "42b963af6cc74d079af04e0a7172a66b",
      "ec3b1a25fc41431f9315d1bf7ec025a3",
      "df36f84cc35348eebbb8328ffa36b1d7",
      "1b0bc9f49eca48b7ac9db7ebb0b91b66",
      "99bf73d2d47946f9987009d52d169124",
      "6a51a87e992b4c7c89ed52536c73df6c",
      "b23c65165c9a4de2b8f8295700a654ee",
      "4ef193e7a0a140cbafd011e0de957da6",
      "d68ce7d597694298b4205c008fe1c1d0",
      "d61ef409355d4df4bac2bb571f0ff4c6",
      "36f6dcab443b4fd99fe02d42045f940c",
      "e706b1192edc488ea722556a7179b2f9",
      "422cf936625a4c669b7dc9caf3e5bf3e",
      "ac6c20d96c0048c7a4f14d093959d694",
      "3868f9913e2e401c96de21bef3f72d5e",
      "09570528083c471eaf57dc52a8b20f67",
      "b57ede20a9f04955b1de859f0ff37a57",
      "5edf636704c8427c927b9be81aefc53c",
      "b19285ca1e024c609d864ed5dc596155",
      "7f3df6ee6f2d496e940eaa766987b1e3",
      "645f8d40d6694bd3a2a768faeb657ad6",
      "a0ba86e538a54d7ebb81371cbd5de7ea",
      "6accbbd1d2324d7aa29c25b4767eee66",
      "bc0068feacd74f819e986fd6f2815f59",
      "936a464d41e7451ca2db94a277009d0c",
      "c87f0a7e39824d76b5e730ca112dcbe8",
      "30ef3415fd644b9c8a213258e75839f1",
      "2fa8d3a4b5574ad19482084971aa89ec",
      "b866f3cd21f24ede8883b0f2bd76ebd3",
      "86ddab92932d407395e76816e965d2c0",
      "f5cda2a7e33541a0bbf419a9bb089cfd",
      "f53497bffabd4a369871c1fb537a4ca9",
      "c7e2d507848b4404b1d84a9743b96179",
      "7752b1f4b48f453b87b90328851e5f87",
      "63538410355348ca9c523eeb92bd7a02",
      "90fc06214b3644c3822be531c487035a",
      "86434aaf3e2f42109e8c23b750315564",
      "b1f5b97ff98849b8b5729ea571677edb",
      "43f910154ef04213b56c6f81cd3e59ca",
      "675d7796798047e68b4721831eecaa12",
      "0111a27f2d464680bc58a86405e526ab",
      "abb11dbd56d849aba6367540d720f045",
      "4ca9dc3bf79d4bc4ad51daea95b9dbbf",
      "898799eb4e234a14bef037efd279fabe",
      "8ecfcb057e1d48cc88052b438b230f25",
      "8b06bb754e5a4171a8744e50c53dda12",
      "dd4d7e1177a7479e8e21775624a5e0a4",
      "bbd88fc6202c49ae8d1e70596b1deea6",
      "30a06b4d531f4737be4bd63eaca541c3",
      "e6afa63fb26245ef808fb82cdacae88b"
     ]
    },
    "id": "8a9zLonssVqF",
    "outputId": "69a323a6-4f15-491f-cea4-a146da65fdc0"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "# Load IMDb dataset\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Load pretrained tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example['text'],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set format for PyTorch\n",
    "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(tokenized_datasets['train'], batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(tokenized_datasets['test'], batch_size=32)\n",
    "\n",
    "# Inspect one batch\n",
    "for batch in train_loader:\n",
    "    print(batch['input_ids'].shape)     # [32, 256]\n",
    "    print(batch['attention_mask'].shape)\n",
    "    print(batch['label'])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6rMIQaPZNa9"
   },
   "source": [
    "POSITIONAL ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5fd5KlFsYMO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len=512):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2) * -(math.log(10000.0) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        self.pe = pe.unsqueeze(0)  # [1, max_len, embed_dim]\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)].to(x.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QEHWRNsZLo-"
   },
   "source": [
    "ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbax7_IU1M84"
   },
   "outputs": [],
   "source": [
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, heads, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, heads, dropout=dropout, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, embed_dim),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, src_mask=None):\n",
    "        attn_output, _ = self.attn(x, x, x, key_padding_mask=src_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.ff(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TldpAlc9ZJpJ"
   },
   "source": [
    "TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cR5FF7tz1PmH"
   },
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, ff_dim, num_layers, num_classes, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        self.pos_encoding = PositionalEncoding(embed_dim)\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerEncoderBlock(embed_dim, num_heads, ff_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        x = self.embedding(input_ids)\n",
    "        x = self.pos_encoding(x)\n",
    "        # Convert attention_mask (1: real, 0: pad) to key_padding_mask (True: pad, False: real)\n",
    "        key_padding_mask = ~attention_mask.bool()\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask=key_padding_mask)\n",
    "        x = x.mean(dim=1)  # Average pooling\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCvW3P1vZGBZ"
   },
   "source": [
    "TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8NOxfmnX4Rmo",
    "outputId": "f8fa72c9-39e0-479b-c72e-f56d5ec1d73f"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = TransformerClassifier(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    embed_dim=128,\n",
    "    num_heads=4,\n",
    "    ff_dim=256,\n",
    "    num_layers=2,\n",
    "    num_classes=2,\n",
    "    pad_idx=tokenizer.pad_token_id\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# For tracking\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Split validation set manually from training set (optional)\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "train_size = int(0.9 * len(tokenized_datasets['train']))\n",
    "val_size = len(tokenized_datasets['train']) - train_size\n",
    "train_dataset, val_dataset = random_split(tokenized_datasets['train'], [train_size, val_size])\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for batch in DataLoader(train_dataset, batch_size=32, shuffle=True):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Validation loss\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    train_losses.append(total_train_loss)\n",
    "    val_losses.append(total_val_loss)\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {total_train_loss:.2f}, Val Loss: {total_val_loss:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN4kiuHlZBfp"
   },
   "source": [
    "VISUALIZING TRAINING AND VALIDATION LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "jzQ-CxGw81Iq",
    "outputId": "e42855af-5741-4976-df8e-db9f72209ba2"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs. Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FX91ALdnY9_7"
   },
   "source": [
    "TEST ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2VrNL2v9JTJ",
    "outputId": "c7e37990-49d5-4c0b-d2b3-d26d2fa5947e"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAJXuzbE-C-J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
